#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç®€åŒ–çš„è®­ç»ƒæµ‹è¯•è„šæœ¬
ç”¨äºéªŒè¯å¤šæ¨¡æ€å‡æ–°é—»æ£€æµ‹ç³»ç»Ÿçš„åŸºæœ¬è®­ç»ƒæµç¨‹
"""

import os
import sys
import torch
import pandas as pd
from torch.utils.data import DataLoader
import logging

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append('/root/models')

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def test_basic_training():
    """
    æµ‹è¯•åŸºæœ¬è®­ç»ƒæµç¨‹
    """
    try:
        logger.info("å¼€å§‹åŸºæœ¬è®­ç»ƒæµ‹è¯•...")
        
        # 1. å¯¼å…¥å¿…è¦æ¨¡å—
        logger.info("å¯¼å…¥æ¨¡å—...")
        from src.models.MultiModalFakeNewsDetector import FakeNewsDataPreprocessor, FakeNewsDataset
        from src.models.text_models.TextProcessingModel import TextProcessingModel
        from src.models.image_models.ImageProcessingModel import ImageProcessingModel
        from src.models.TransformerFusionModel import create_fusion_model
        
        # 2. åˆå§‹åŒ–æ•°æ®é¢„å¤„ç†å™¨
        logger.info("åˆå§‹åŒ–æ•°æ®é¢„å¤„ç†å™¨...")
        preprocessor = FakeNewsDataPreprocessor()
        
        # 3. æ£€æŸ¥é¢„å¤„ç†å™¨ä¸­çš„æ•°æ®
        logger.info("æ£€æŸ¥é¢„å¤„ç†å™¨æ•°æ®...")
        logger.info(f"è®­ç»ƒæ•°æ®å¤§å°: {len(preprocessor.train_df)}")
        logger.info(f"éªŒè¯æ•°æ®å¤§å°: {len(preprocessor.val_df)}")
        logger.info(f"æµ‹è¯•æ•°æ®å¤§å°: {len(preprocessor.test_df)}")
        
        # æ£€æŸ¥æ•°æ®ç±»å‹
        sample_text = preprocessor.train_df.iloc[0]['text']
        logger.info(f"æ ·æœ¬æ–‡æœ¬ç±»å‹: {type(sample_text)}")
        logger.info(f"æ ·æœ¬æ–‡æœ¬å†…å®¹: {str(sample_text)[:100]}...")
        
        # 4. åˆ›å»ºæ•°æ®é›†
        logger.info("åˆ›å»ºæ•°æ®é›†...")
        train_dataset = FakeNewsDataset(
            preprocessor=preprocessor,
            split='dev',
            max_samples=50,  # ä½¿ç”¨å°æ ·æœ¬è¿›è¡Œæµ‹è¯•
            device='cuda' if torch.cuda.is_available() else 'cpu',
            use_cache=False,  # ç¦ç”¨ç¼“å­˜ä»¥é¿å…é—®é¢˜
            augment_text=False
        )
        
        # 5. åˆ›å»ºæ•°æ®åŠ è½½å™¨
        train_loader = DataLoader(
            train_dataset,
            batch_size=2,  # ä½¿ç”¨å°æ‰¹é‡è¿›è¡Œæµ‹è¯•
            shuffle=True,
            num_workers=0  # é¿å…å¤šè¿›ç¨‹é—®é¢˜
        )
        
        # 6. æµ‹è¯•æ•°æ®åŠ è½½
        logger.info("æµ‹è¯•æ•°æ®åŠ è½½...")
        for i, batch in enumerate(train_loader):
            if i >= 2:  # åªæµ‹è¯•å‰2ä¸ªæ‰¹æ¬¡
                break
            logger.info(f"æ‰¹æ¬¡ {i+1}:")
            logger.info(f"  - text_features: {batch['text_features'].shape}")
            logger.info(f"  - image_features: {batch['image_features'].shape}")
            logger.info(f"  - label: {batch['label'].shape}")
        
        # 7. åˆ›å»ºç®€åŒ–çš„èåˆæ¨¡å‹
        logger.info("åˆ›å»ºç®€åŒ–èåˆæ¨¡å‹...")
        
        class SimpleFusionModel(torch.nn.Module):
            def __init__(self, text_dim=768, image_dim=768, hidden_dim=256, num_classes=2):
                super().__init__()
                self.text_proj = torch.nn.Linear(text_dim, hidden_dim)
                self.image_proj = torch.nn.Linear(image_dim, hidden_dim)
                self.fusion = torch.nn.Linear(hidden_dim * 2, hidden_dim)
                self.classifier = torch.nn.Linear(hidden_dim, num_classes)
                self.dropout = torch.nn.Dropout(0.1)
                
            def forward(self, text_features, image_features):
                # æŠ•å½±åˆ°ç›¸åŒç»´åº¦
                text_proj = self.text_proj(text_features.squeeze(1))  # å»æ‰batchç»´åº¦
                image_proj = self.image_proj(image_features.squeeze(1))
                
                # èåˆç‰¹å¾
                fused = torch.cat([text_proj, image_proj], dim=1)
                fused = self.fusion(fused)
                fused = torch.relu(fused)
                fused = self.dropout(fused)
                
                # åˆ†ç±»
                logits = self.classifier(fused)
                return logits
        
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
        fusion_model = SimpleFusionModel().to(device)
        logger.info(f"æ¨¡å‹å·²ç§»åŠ¨åˆ°è®¾å¤‡: {device}")
        
        # 8. æµ‹è¯•æ¨¡å‹å‰å‘ä¼ æ’­
        logger.info("æµ‹è¯•æ¨¡å‹å‰å‘ä¼ æ’­...")
        fusion_model.eval()
        
        with torch.no_grad():
            for i, batch in enumerate(train_loader):
                if i >= 1:  # åªæµ‹è¯•1ä¸ªæ‰¹æ¬¡
                    break
                
                outputs = fusion_model(
                    batch['text_features'],
                    batch['image_features']
                )
                
                logger.info(f"æ¨¡å‹è¾“å‡ºå½¢çŠ¶: {outputs.shape}")
                logger.info(f"é¢„æµ‹æ¦‚ç‡: {torch.softmax(outputs, dim=1)}")
                break
        
        # 9. æµ‹è¯•ç®€å•è®­ç»ƒæ­¥éª¤
        logger.info("æµ‹è¯•è®­ç»ƒæ­¥éª¤...")
        fusion_model.train()
        optimizer = torch.optim.Adam(fusion_model.parameters(), lr=1e-4)
        criterion = torch.nn.CrossEntropyLoss()
        
        for i, batch in enumerate(train_loader):
            if i >= 2:  # åªè®­ç»ƒ2ä¸ªæ‰¹æ¬¡
                break
            
            optimizer.zero_grad()
            
            outputs = fusion_model(
                batch['text_features'],
                batch['image_features']
            )
            
            loss = criterion(outputs, batch['label'])
            loss.backward()
            optimizer.step()
            
            logger.info(f"æ‰¹æ¬¡ {i+1}, æŸå¤±: {loss.item():.4f}")
        
        logger.info("âœ“ åŸºæœ¬è®­ç»ƒæµ‹è¯•å®Œæˆï¼")
        return True
        
    except Exception as e:
        logger.error(f"è®­ç»ƒæµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = test_basic_training()
    if success:
        print("\nğŸ‰ åŸºæœ¬è®­ç»ƒæµ‹è¯•æˆåŠŸï¼ç³»ç»Ÿå¯ä»¥è¿›è¡Œè®­ç»ƒã€‚")
    else:
        print("\nâŒ åŸºæœ¬è®­ç»ƒæµ‹è¯•å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥è°ƒè¯•ã€‚")