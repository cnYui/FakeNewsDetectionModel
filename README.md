# å¤šæ¨¡æ€è™šå‡æ–°é—»æ£€æµ‹ç³»ç»Ÿ

ä¸€ä¸ªåŸºäºæ·±åº¦å­¦ä¹ çš„å¤šæ¨¡æ€è™šå‡æ–°é—»æ£€æµ‹ç³»ç»Ÿï¼Œç»“åˆæ–‡æœ¬å’Œå›¾åƒç‰¹å¾è¿›è¡Œè™šå‡æ–°é—»è¯†åˆ«ã€‚

## é¡¹ç›®æ¦‚è¿°

æœ¬é¡¹ç›®å®ç°äº†ä¸€ä¸ªå…ˆè¿›çš„å¤šæ¨¡æ€è™šå‡æ–°é—»æ£€æµ‹ç³»ç»Ÿï¼Œé€šè¿‡èåˆæ–‡æœ¬å’Œå›¾åƒç‰¹å¾æ¥è¯†åˆ«è™šå‡æ–°é—»ã€‚ç³»ç»Ÿé‡‡ç”¨äº†BERTä¸­æ–‡æ¨¡å‹å¤„ç†æ–‡æœ¬ï¼ŒCLIPæ¨¡å‹å¤„ç†å›¾åƒï¼Œå¹¶é€šè¿‡Transformeræ¶æ„è¿›è¡Œå¤šæ¨¡æ€ç‰¹å¾èåˆã€‚

### æ ¸å¿ƒç‰¹æ€§
- **å¤šæ¨¡æ€èåˆ**: ç»“åˆæ–‡æœ¬å’Œå›¾åƒç‰¹å¾è¿›è¡Œç»¼åˆåˆ¤æ–­
- **ä¸­æ–‡ä¼˜åŒ–**: ä¸“é—¨é’ˆå¯¹ä¸­æ–‡æ–°é—»æ–‡æœ¬è¿›è¡Œä¼˜åŒ–
- **æ·±åº¦å­¦ä¹ **: åŸºäºBERTã€CLIPç­‰å…ˆè¿›é¢„è®­ç»ƒæ¨¡å‹
- **ç«¯åˆ°ç«¯è®­ç»ƒ**: æ”¯æŒå®Œæ•´çš„è®­ç»ƒå’Œæ¨ç†æµç¨‹
- **é«˜æ€§èƒ½**: GPUåŠ é€Ÿè®­ç»ƒï¼Œæ”¯æŒå¤§è§„æ¨¡æ•°æ®é›†

## é¡¹ç›®ç»“æ„

```
â”œâ”€â”€ README.md                    # é¡¹ç›®ä¸»æ–‡æ¡£
â”œâ”€â”€ TODO_REPRODUCTION.md         # å¤ç°è¿›åº¦è·Ÿè¸ª
â”œâ”€â”€ .gitattributes              # Gitå±æ€§é…ç½®
â”œâ”€â”€ .gitignore                  # Gitå¿½ç•¥æ–‡ä»¶
â”œâ”€â”€ configs/                    # é…ç½®æ–‡ä»¶ç›®å½•
â”œâ”€â”€ docs/                       # æ–‡æ¡£ç›®å½•
â”‚   â”œâ”€â”€ README.md              # è¯¦ç»†é¡¹ç›®æ–‡æ¡£
â”‚   â””â”€â”€ å¤šæ¨¡æ€è™šå‡æ–°é—»æ£€æµ‹æ¨¡å‹æŠ€æœ¯æ–‡æ¡£.md
â”œâ”€â”€ pretrained_models/          # é¢„è®­ç»ƒæ¨¡å‹å­˜æ”¾ç›®å½•
â”‚   â”œâ”€â”€ bert-base-chinese/     # BERTä¸­æ–‡æ¨¡å‹ (å·²ä¸‹è½½)
â”‚   â”œâ”€â”€ clip-vit-base-patch32/ # CLIPæ¨¡å‹ (å·²ä¸‹è½½)
â”‚   â””â”€â”€ resnet-18/             # ResNet-18æ¨¡å‹
â”œâ”€â”€ scripts/                    # è„šæœ¬ç›®å½•
â”‚   â”œâ”€â”€ download_bert_chinese.py    # BERTæ¨¡å‹ä¸‹è½½è„šæœ¬
â”‚   â”œâ”€â”€ download_clip_model.py      # CLIPæ¨¡å‹ä¸‹è½½è„šæœ¬
â”‚   â”œâ”€â”€ install_dependencies.sh     # ä¾èµ–å®‰è£…è„šæœ¬
â”‚   â”œâ”€â”€ load_pretrained_text_model.py
â”‚   â””â”€â”€ quick_start_reproduction.sh # å¿«é€Ÿå¤ç°è„šæœ¬
â””â”€â”€ src/                        # æºä»£ç ç›®å½•
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ data_processing/        # æ•°æ®å¤„ç†æ¨¡å—
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ chinese_text_augmentation.py
    â”‚   â””â”€â”€ text_augmentation.py
    â”œâ”€â”€ models/                 # æ¨¡å‹å®šä¹‰
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ MultiModalFakeNewsDetector.py  # ä¸»æ£€æµ‹å™¨
    â”‚   â”œâ”€â”€ TransformerFusionModel.py      # èåˆæ¨¡å‹
    â”‚   â”œâ”€â”€ clip_loader.py              # CLIPæ¨¡å‹åŠ è½½å™¨
    â”‚   â”œâ”€â”€ download_nltk_data.py       # NLTKæ•°æ®ä¸‹è½½
    â”‚   â”œâ”€â”€ inference.py                # æ¨ç†æ¥å£
    â”‚   â”œâ”€â”€ train_fusion_model.py       # è®­ç»ƒè„šæœ¬
    â”‚   â”œâ”€â”€ image_models/       # å›¾åƒæ¨¡å‹
    â”‚   â”‚   â”œâ”€â”€ ImageProcessingModel.py
    â”‚   â”‚   â””â”€â”€ SimpleImageModel.py
    â”‚   â””â”€â”€ text_models/        # æ–‡æœ¬æ¨¡å‹
    â”‚       â”œâ”€â”€ TextProcessingModel.py
    â”‚       â”œâ”€â”€ WordClassification.py
    â”‚       â”œâ”€â”€ evaluate_model.py
    â”‚       â””â”€â”€ train_bert_only.py
    â”œâ”€â”€ training/               # è®­ç»ƒç›¸å…³
    â”‚   â””â”€â”€ __init__.py
    â””â”€â”€ utils/                  # å·¥å…·å‡½æ•°
        â””â”€â”€ __init__.py
```

## ç¯å¢ƒè¦æ±‚

### ç³»ç»Ÿè¦æ±‚
- **æ“ä½œç³»ç»Ÿ**: Linux (æ¨è Ubuntu 18.04+)
- **Python**: 3.8+ (å½“å‰ç¯å¢ƒ: Python 3.10.8)
- **GPU**: NVIDIA GPU with CUDA 11.0+ (å½“å‰: CUDA 12.1)
- **å†…å­˜**: 16GB+ RAM æ¨è
- **å­˜å‚¨**: 10GB+ å¯ç”¨ç©ºé—´

### å·²å®‰è£…ä¾èµ–
å½“å‰ç¯å¢ƒå·²å®‰è£…ä»¥ä¸‹æ ¸å¿ƒä¾èµ–ï¼š
- `torch==2.1.2+cu121` - PyTorchæ·±åº¦å­¦ä¹ æ¡†æ¶
- `transformers==4.51.3` - Hugging Face Transformers
- `numpy==1.26.3` - æ•°å€¼è®¡ç®—
- `pandas==2.2.3` - æ•°æ®å¤„ç†
- `pillow==10.2.0` - å›¾åƒå¤„ç†
- `scikit-learn==1.6.1` - æœºå™¨å­¦ä¹ å·¥å…·
- `matplotlib==3.8.2` - æ•°æ®å¯è§†åŒ–
- `seaborn==0.13.2` - ç»Ÿè®¡å¯è§†åŒ–
- `jieba==0.42.1` - ä¸­æ–‡åˆ†è¯
- `tqdm==4.64.1` - è¿›åº¦æ¡

## å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒéªŒè¯
```bash
# æ£€æŸ¥Pythonç‰ˆæœ¬
python --version

# æ£€æŸ¥CUDAå¯ç”¨æ€§
python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}'); print(f'CUDA version: {torch.version.cuda}'); print(f'GPU count: {torch.cuda.device_count()}')"
```

### 2. é¢„è®­ç»ƒæ¨¡å‹çŠ¶æ€
é¢„è®­ç»ƒæ¨¡å‹å·²æˆåŠŸä¸‹è½½å¹¶éªŒè¯ï¼š
- âœ… **BERTä¸­æ–‡æ¨¡å‹**: `/root/autodl-tmp/model_cache_new/bert-base-chinese/`
- âœ… **CLIPæ¨¡å‹**: `/root/autodl-tmp/model_cache_new/clip-vit-base-patch32/`

æ¨¡å‹åŠ è½½æµ‹è¯•é€šè¿‡ï¼š
```bash
# éªŒè¯æ¨¡å‹åŠ è½½
python -c "
from transformers import BertModel, CLIPModel
bert = BertModel.from_pretrained('/root/autodl-tmp/model_cache_new/bert-base-chinese')
clip = CLIPModel.from_pretrained('/root/autodl-tmp/model_cache_new/clip-vit-base-patch32')
print(f'BERT hidden size: {bert.config.hidden_size}')
print(f'CLIP vision hidden size: {clip.config.vision_config.hidden_size}')
"
```

### 3. æ•°æ®é›†å‡†å¤‡
æ•°æ®é›†ä½äº `/root/autodl-tmp/data/`ï¼ŒåŒ…å«ï¼š
- `train.csv` - è®­ç»ƒé›† (9,740æ¡è®°å½•)
- `val.csv` - éªŒè¯é›† (1,083æ¡è®°å½•)  
- `test.csv` - æµ‹è¯•é›† (2,454æ¡è®°å½•)
- `images/` - å›¾åƒæ–‡ä»¶ç›®å½•

æ•°æ®æ ¼å¼ï¼š
```csv
path,text,label
./data/images/image_name.jpg,æ–°é—»æ–‡æœ¬å†…å®¹,0/1
```

### 4. æ¨¡å‹è®­ç»ƒ
```bash
# è¿›å…¥æ¨¡å‹ç›®å½•
cd /root/models/src/models

# å¼€å§‹è®­ç»ƒ
python train_fusion_model.py \
    --data_dir /root/autodl-tmp/data \
    --model_cache_dir /root/autodl-tmp/model_cache_new \
    --images_dir /root/autodl-tmp/data/images \
    --batch_size 16 \
    --epochs 10 \
    --learning_rate 2e-5
```

### 5. æ¨¡å‹æ¨ç†
```bash
# å•æ ·æœ¬æ¨ç†
python inference.py \
    --text "æ–°é—»æ–‡æœ¬å†…å®¹" \
    --image_path "/path/to/image.jpg" \
    --model_path "/path/to/trained/model.pth"

# æ‰¹é‡æ¨ç†
python MultiModalFakeNewsDetector.py
```

## æ ¸å¿ƒæ¨¡å—

### 1. æ–‡æœ¬å¤„ç†æ¨¡å—
- **BERTä¸­æ–‡ç¼–ç **: ä½¿ç”¨ `bert-base-chinese` è¿›è¡Œæ–‡æœ¬ç‰¹å¾æå–
- **ä¸­æ–‡åˆ†è¯**: åŸºäº jieba çš„ä¸­æ–‡æ–‡æœ¬é¢„å¤„ç†
- **æ–‡æœ¬å¢å¼º**: æ”¯æŒåŒä¹‰è¯æ›¿æ¢ã€éšæœºåˆ é™¤ç­‰æ•°æ®å¢å¼ºæŠ€æœ¯

### 2. å›¾åƒå¤„ç†æ¨¡å—
- **CLIPè§†è§‰ç¼–ç **: ä½¿ç”¨ `clip-vit-base-patch32` è¿›è¡Œå›¾åƒç‰¹å¾æå–
- **å›¾åƒé¢„å¤„ç†**: æ ‡å‡†åŒ–ã€ç¼©æ”¾ã€æ•°æ®å¢å¼º
- **å¤šå°ºåº¦ç‰¹å¾**: æ”¯æŒä¸åŒåˆ†è¾¨ç‡çš„å›¾åƒè¾“å…¥

### 3. å¤šæ¨¡æ€èåˆæ¨¡å—
- **Transformerèåˆ**: åŸºäºæ³¨æ„åŠ›æœºåˆ¶çš„ç‰¹å¾èåˆ
- **è·¨æ¨¡æ€å¯¹é½**: æ–‡æœ¬å’Œå›¾åƒç‰¹å¾çš„è¯­ä¹‰å¯¹é½
- **ç‰¹å¾äº¤äº’**: æ·±åº¦ç‰¹å¾äº¤äº’å’Œä¿¡æ¯æ•´åˆ

### 4. è®­ç»ƒä¸è¯„ä¼°
- **ç«¯åˆ°ç«¯è®­ç»ƒ**: æ”¯æŒå¤šæ¨¡æ€è”åˆè®­ç»ƒ
- **è¯„ä¼°æŒ‡æ ‡**: å‡†ç¡®ç‡ã€ç²¾ç¡®ç‡ã€å¬å›ç‡ã€F1åˆ†æ•°
- **æ¨¡å‹ä¿å­˜**: æ”¯æŒæ¨¡å‹æ£€æŸ¥ç‚¹å’Œæœ€ä½³æ¨¡å‹ä¿å­˜

## æŠ€æœ¯æ¶æ„

```
è¾“å…¥å±‚
â”œâ”€â”€ æ–‡æœ¬è¾“å…¥ â†’ BERTç¼–ç å™¨ â†’ æ–‡æœ¬ç‰¹å¾ (768ç»´)
â””â”€â”€ å›¾åƒè¾“å…¥ â†’ CLIPç¼–ç å™¨ â†’ å›¾åƒç‰¹å¾ (512ç»´)
                    â†“
              ç‰¹å¾èåˆå±‚
         (Transformer + æ³¨æ„åŠ›æœºåˆ¶)
                    â†“
               åˆ†ç±»å™¨å±‚
            (å…¨è¿æ¥ + Dropout)
                    â†“
              è¾“å‡º (çœŸ/å‡)
```

## æ€§èƒ½æŒ‡æ ‡

### æ•°æ®é›†ç»Ÿè®¡
- **æ€»æ ·æœ¬æ•°**: 13,277æ¡
- **è®­ç»ƒé›†**: 9,740æ¡ (73.4%)
- **éªŒè¯é›†**: 1,083æ¡ (8.2%)
- **æµ‹è¯•é›†**: 2,454æ¡ (18.5%)
- **æ ‡ç­¾åˆ†å¸ƒ**: å‡æ–°é—»çº¦å 60%ï¼ŒçœŸæ–°é—»çº¦å 40%

### æ¨¡å‹æ€§èƒ½ (é¢„æœŸ)
- **å‡†ç¡®ç‡**: >85%
- **F1åˆ†æ•°**: >0.83
- **è®­ç»ƒæ—¶é—´**: ~2-4å°æ—¶ (å•GPU)
- **æ¨ç†é€Ÿåº¦**: ~100ms/æ ·æœ¬

## ä½¿ç”¨ç¤ºä¾‹

### Python API
```python
from src.models.MultiModalFakeNewsDetector import MultiModalFakeNewsDetector

# åˆå§‹åŒ–æ£€æµ‹å™¨
detector = MultiModalFakeNewsDetector(
    model_cache_dir='/root/autodl-tmp/model_cache_new'
)

# åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
detector.load_model('path/to/trained/model.pth')

# è¿›è¡Œé¢„æµ‹
result = detector.predict(
    text="æ–°é—»æ–‡æœ¬å†…å®¹",
    image_path="/path/to/image.jpg"
)

print(f"é¢„æµ‹ç»“æœ: {'å‡æ–°é—»' if result['prediction'] == 1 else 'çœŸæ–°é—»'}")
print(f"ç½®ä¿¡åº¦: {result['confidence']:.3f}")
```

### å‘½ä»¤è¡Œå·¥å…·
```bash
# è®­ç»ƒæ¨¡å‹
python src/models/train_fusion_model.py \
    --data_dir /root/autodl-tmp/data \
    --epochs 10 \
    --batch_size 16

# è¯„ä¼°æ¨¡å‹
python src/models/evaluate_model.py \
    --model_path /path/to/model.pth \
    --test_data /root/autodl-tmp/data/test.csv

# å•æ ·æœ¬æ¨ç†
python src/models/inference.py \
    --text "æ–°é—»æ–‡æœ¬" \
    --image "/path/to/image.jpg"
```

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **CUDAå†…å­˜ä¸è¶³**
   ```bash
   # å‡å°æ‰¹æ¬¡å¤§å°
   python train_fusion_model.py --batch_size 8
   ```

2. **æ¨¡å‹åŠ è½½å¤±è´¥**
   ```bash
   # æ£€æŸ¥æ¨¡å‹è·¯å¾„
   ls -la /root/autodl-tmp/model_cache_new/
   ```

3. **å›¾åƒæ–‡ä»¶ç¼ºå¤±**
   ```bash
   # æ£€æŸ¥å›¾åƒç›®å½•
   ls -la /root/autodl-tmp/data/images/ | head -10
   ```

### æ€§èƒ½ä¼˜åŒ–

- **æ··åˆç²¾åº¦è®­ç»ƒ**: ä½¿ç”¨ `--fp16` æ ‡å¿—
- **æ¢¯åº¦ç´¯ç§¯**: ä½¿ç”¨ `--gradient_accumulation_steps`
- **æ•°æ®å¹¶è¡Œ**: å¤šGPUè®­ç»ƒæ”¯æŒ

## é¡¹ç›®çŠ¶æ€

å½“å‰å¤ç°è¿›åº¦ï¼š
- âœ… ç¯å¢ƒé…ç½®å®Œæˆ
- âœ… é¢„è®­ç»ƒæ¨¡å‹ä¸‹è½½å®Œæˆ
- âœ… æ•°æ®é›†å‡†å¤‡å®Œæˆ
- âœ… ä»£ç è·¯å¾„é…ç½®å®Œæˆ
- ğŸ”„ æ¨¡å‹è®­ç»ƒè¿›è¡Œä¸­
- â³ æ¨¡å‹è¯„ä¼°å¾…å®Œæˆ
- â³ æ€§èƒ½ä¼˜åŒ–å¾…å®Œæˆ

è¯¦ç»†è¿›åº¦è¯·æŸ¥çœ‹ `TODO_REPRODUCTION.md`

## è´¡çŒ®æŒ‡å—

æ¬¢è¿æäº¤Issueå’ŒPull Requestæ¥æ”¹è¿›é¡¹ç›®ã€‚

## è®¸å¯è¯

MIT License

## è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜ï¼Œè¯·é€šè¿‡GitHub Issuesè”ç³»ã€‚